<html><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>Overview - CMUcam5 Pixy - CMUcam: Open Source Programmable Embedded Color Vision Sensors</title>
<meta name="description" content="Redmine">
<meta name="keywords" content="issue,bug,tracker">
<meta name="csrf-param" content="authenticity_token">
<meta name="csrf-token" content="6JcSZoavTFr2KQ2uXGIHCwXdHPAN5YlDNDE1zQDiLas=">
<link rel="shortcut icon" href="http://cmucam.org/favicon.ico?1353443604">
<link href="application.css" media="all" rel="stylesheet" type="text/css">

<script type="text/javascript" async="" src="ga"></script><script type="text/javascript" async="" src="ga"></script><script src="prototype.js" type="text/javascript"></script>
<script src="effects.js" type="text/javascript"></script>
<script src="dragdrop.js" type="text/javascript"></script>
<script src="controls.js" type="text/javascript"></script>
<script src="application.js" type="text/javascript"></script>
<script type="text/javascript">
//<![CDATA[
Event.observe(window, 'load', function(){ new WarnLeavingUnsaved('The current page contains unsaved text that will be lost if you leave this page.'); });
//]]>
</script>

<!--[if IE 6]>
    <style type="text/css">
      * html body{ width: expression( document.documentElement.clientWidth < 900 ? '900px' : '100%' ); }
      body {behavior: url(/stylesheets/csshover.htc?1328475261);}
    </style>
<![endif]-->

<!-- page specific tags -->

<link href="http://thin_cluster/projects/cmucam5/activity.atom" rel="alternate" title="ATOM" type="application/atom+xml">
</head>
<body class="theme-Modula martini controller-projects action-show">
<div id="wrapper">
<div id="wrapper2">
<div id="top-menu">
    <div id="account">
        <ul><li><a href="http://cmucam.org/login" class="login">Sign in</a></li>
<li><a href="http://cmucam.org/account/register" class="register">Register</a></li></ul>    </div>
    
    <ul><li><a href="http://cmucam.org/" class="home">Home</a></li>
<li><a href="http://cmucam.org/projects" class="projects">Projects</a></li>
<li><a href="http://www.redmine.org/guide" class="help">Help</a></li></ul></div>

<div id="header">
    
    <div id="quick-search">
        <form action="/search/index/cmucam5" method="get">
        
        <label for="q">
          <a href="http://cmucam.org/search/index/cmucam5" accesskey="4">Search</a>:
        </label>
        <input accesskey="f" class="small" id="q" name="q" size="20" type="text">
        </form>
        
    </div>
    

    <h1>CMUcam5 Pixy</h1>

    
    <div id="main-menu">
        <ul><li><a href="http://cmucam.org/projects/cmucam5" class="overview selected">Overview</a></li>
<li><a href="http://cmucam.org/projects/cmucam5/activity" class="activity">Activity</a></li>
<li><a href="http://cmucam.org/projects/cmucam5/news" class="news">News</a></li>
<li><a href="http://cmucam.org/projects/cmucam5/documents" class="documents">Documents</a></li>
<li><a href="http://cmucam.org/projects/cmucam5/wiki" class="wiki">Wiki</a></li>
<li><a href="http://cmucam.org/projects/cmucam5/boards" class="boards">Forums</a></li>
<li><a href="http://cmucam.org/projects/cmucam5/files" class="files">Files</a></li></ul>
    </div>
    
</div>

<div class="" id="main">
    <div id="sidebar">
        
    
    

        
    </div>

    <div id="content">
        
        <div class="contextual">
  
</div>

<h2>Overview</h2>

<div class="splitcontentleft">
  <div class="wiki">
    <p><img src="inhand_zpsb2d6b768.jpg" style="width: 35%;" alt=""></p>


	<ul>
	<li>Small, fast, easy-to-use, low-cost, readily-available vision system</li>
		<li>Learns to detect objects that you teach it</li>
		<li>Outputs what it detects 50 times per second</li>
		<li>Connects to Arduino with included cable. Also works with Raspberry Pi, BeagleBone and similar controllers</li>
		<li>All libraries for Arduino, Raspberry Pi, etc. are provided</li>
		<li>C/C++ and Python are supported</li>
		<li>Communicates via one of several interfaces: SPI, I2C, UART, USB or analog/digital output</li>
		<li>Configuration utility runs on Windows, MacOS and Linux</li>
		<li>All software/firmare is open-source GNU-licensed </li>
		<li>All hardware documentation including schematics, bill of materials, PCB layout, etc. are provided</li>
	</ul>


	<a name="How-Pixy-got-started"></a>
<h2><strong>How Pixy got started</strong><a href="#How-Pixy-got-started" class="wiki-anchor">¶</a></h2>


	<p>Pixy (CMUcam5) is a partnership between the Carnegie Mellon Robotics
 Institute and Charmed Labs.  Pixy comes from a long line of CMUcams, 
but Pixy got its real start as a <a href="https://www.kickstarter.com/projects/254449872/pixy-cmucam5-a-fast-easy-to-use-vision-sensor" class="external">Kickstarter campaign</a>.  It first started shipping in March of 2014, but it's already become <strong>the most popular vision system in history</strong>!
  Pixy is funded exclusively through sales, so thank you for making Pixy
 a success!  You can watch the original Kickstarter video below -- it's a
 good introduction!</p>


	<p><object width=" 480" height=" 360">
  <param name="movie" value="http://www.youtube.com/v/J8sl3nMlYxM?rel=1&amp;fs=1">
  <param name="allowFullScreen" value="true">
  <param name="allowScriptAccess" value="always">
  <embed src="J8sl3nMlYxM" type="application/x-shockwave-flash" allowscriptaccess="always" allowfullscreen="true" width=" 480" height=" 360">
</object>
</p>


	<a name="Vision-as-a-Sensor"></a>
<h2><strong>Vision as a Sensor</strong><a href="#Vision-as-a-Sensor" class="wiki-anchor">¶</a></h2>


	<p>If you want your robot to perform a task such as picking up an 
object, chasing a ball, locating a charging station, etc., and you want a
 single sensor to help accomplish all of these tasks, then <strong>vision</strong>
 is your sensor.  Vision (image) sensors are useful because they are so 
flexible. With the right algorithm, an image sensor can sense or detect 
practically anything.  But there are two drawbacks with image sensors: 
1) they output lots of data, dozens of megabytes per second, and 2) 
processing this amount of data can overwhelm many processors.  And if 
the processor can keep up with the data, much of its processing power 
won't be available for other tasks.</p>


	<p>Pixy addresses these problems by pairing a powerful dedicated 
processor with the image sensor.  Pixy processes images from the image 
sensor and only sends the useful information (e.g. purple dinosaur 
detected at x=54, y=103) to your microcontroller.  And it does this at 
frame rate (50 Hz).  The information is available through one of several
 interfaces: UART serial, SPI, I2C, USB, or digital/analog output.  So 
your Arduino or other microcontroller can talk easily with Pixy and 
still have plenty of CPU available for other tasks.</p>


	<p>It's possible to hook up multiple Pixys to your microcontroller -- 
for example, a robot with 4 Pixys and 360 degrees of sensing.  Or use 
Pixy without a microcontroller and use the digital or analog outputs to 
trigger events, switches, servos, etc.</p>


	<a name="Controller-support"></a>
<h2><strong>Controller support</strong><a href="#Controller-support" class="wiki-anchor">¶</a></h2>


	<p>Pixy can easily connect to lots of different controllers because it 
supports several interface options (UART serial, SPI, I2C, USB, or 
digital/analog output), but Pixy began its life talking to Arduinos.  
Over the last several months we've added support for Arduino Due, 
Raspberry Pi and BeagleBone Black.  Software libraries are provided for 
all of these platforms so you can get up and running quickly.  
Additionally, we've added a Python API if you're using a Linux-based 
controller (e.g. Raspberry Pi, BeagleBone).</p>


	<a name="Purple-dinosaurs-and-other-things"></a>
<h2><strong>Purple dinosaurs (and other things)</strong><a href="#Purple-dinosaurs-and-other-things" class="wiki-anchor">¶</a></h2>


	<p>Pixy uses a color-based filtering algorithm to detect objects.  
Color-based filtering methods are popular because they are fast, 
efficient, and relatively robust.  Most of us are familiar with RGB 
(red, green, and blue) to represent colors.  Pixy calculates the color 
(hue) and saturation of each RGB pixel from the image sensor and uses 
these as the primary filtering parameters.  The hue of an object remains
 largely unchanged with changes in lighting and exposure.  Changes in 
lighting and exposure can have a frustrating effect on color filtering 
algorithms, causing them to break.  Pixy’s filtering algorithm is robust
 when it comes to lighting and exposure changes.</p>


	<a name="Seven-color-signatures"></a>
<h2><strong>Seven color signatures</strong><a href="#Seven-color-signatures" class="wiki-anchor">¶</a></h2>


	<p>Pixy remembers up to 7 different color signatures, which means that 
if you have 7 different objects with unique colors, Pixy’s color 
filtering algorithm will have no problem identifying them.  If you need 
more than seven, you can use color codes (see below).</p>


	<a name="Hundreds-of-objects"></a>
<h2><strong>Hundreds of objects</strong><a href="#Hundreds-of-objects" class="wiki-anchor">¶</a></h2>


	<p>Pixy can find literally hundreds of objects at a time.  It uses a 
connected components algorithm to determine where one object begins and 
another ends.  Pixy then compiles the sizes and locations of each object
 and reports them through one of its interfaces (e.g. SPI).</p>


	<a name="50-frames-per-second"></a>
<h2><strong>50 frames per second</strong><a href="#50-frames-per-second" class="wiki-anchor">¶</a></h2>


	<p>What does “50 frames per second” mean?  In short, it means Pixy is 
fast.  Pixy processes an entire 640x400 image frame every 1/50th of a 
second (20 milliseconds).  This means that you get a complete update of 
all detected objects' positions every 20 ms.  At this rate, tracking the
 path of falling/bouncing ball is possible.  (A ball traveling at 30 mph
 moves less than a foot in 20 ms.)</p>


	<a name="Teach-it-the-objects-youre-interested-in"></a>
<h2><strong>Teach it the objects you're interested in</strong><a href="#Teach-it-the-objects-youre-interested-in" class="wiki-anchor">¶</a></h2>


	<p>Pixy is unique because you can physically teach it what you are 
interested in sensing.  Purple dinosaur?  Place the dinosaur in front of
 Pixy and press the button.  Orange ball?  Place the ball in front of 
Pixy and press the button.  It’s easy, and it's fast.</p>


	<p>More specifically, you teach Pixy by holding the object in front of 
its lens while holding down the button located on top.  While doing 
this, the RGB LED under the lens provides feedback regarding which 
object it is looking at directly.  For example, the LED turns orange 
when an orange ball is placed directly in front of Pixy.  Release the 
button and Pixy generates a statistical model of the colors contained in
 the object and stores them in flash.  It will then use this statistical
 model to find objects with similar color signatures in its frame from 
then on.</p>


	<p>Pixy can learn seven color signatures, numbered 1-7.  Color 
signature 1 is the default signature.  To teach Pixy the other 
signatures (2-7) requires a simple button pressing sequence.</p>


	<p><object width=" 480" height=" 360">
  <param name="movie" value="http://www.youtube.com/v/7znEmgYZXL0?rel=1&amp;fs=1">
  <param name="allowFullScreen" value="true">
  <param name="allowScriptAccess" value="always">
  <embed src="7znEmgYZXL0" type="application/x-shockwave-flash" allowscriptaccess="always" allowfullscreen="true" width=" 480" height=" 360">
</object>
</p>


	<a name="PixyMon-lets-you-see-what-Pixy-sees"></a>
<h2><strong>PixyMon lets you see what Pixy sees</strong><a href="#PixyMon-lets-you-see-what-Pixy-sees" class="wiki-anchor">¶</a></h2>


	<p>PixyMon is an application that runs on Windows, MacOs and Linux.  It
 allows you to see what Pixy sees, either as raw or processed video.  It
 also allows you to configure your Pixy, set the output port and manage 
color signatures.  PixyMon communicates with Pixy over a standard mini 
USB cable.</p>


	<p>PixyMon is great for debugging your application.  You can plug a USB
 cable into the back of Pixy and run PixyMon and then see what Pixy sees
 while it is hooked to your Arduino or other microcontroller -- no need 
to unplug anything.  PixyMon is open source, like everything else.</p>


	<p><img src="Image209_zps1e87977b.jpg" style="width: 70%;" alt=""></p>


	<a name="Technical-specs"></a>
<h2><strong>Technical specs</strong><a href="#Technical-specs" class="wiki-anchor">¶</a></h2>


	<ul>
	<li>Processor: NXP  LPC4330, 204 MHz, dual core</li>
		<li>Image sensor: Omnivision OV9715, 1/4", 1280x800</li>
		<li>Lens field-of-view: 75 degrees horizontal, 47 degrees vertical</li>
		<li>Lens type: standard M12 (several different types available)</li>
		<li>Power consumption: 140 mA typical</li>
		<li>Power input: USB input (5V) or unregulated input (6V to 10V)</li>
		<li>RAM: 264K bytes</li>
		<li>Flash: 1M bytes</li>
		<li>Available data outputs: UART serial, SPI, I2C, USB, digital, analog</li>
		<li>Dimensions: 2.1" x 2.0" x 1.4</li>
		<li>Weight: 27 grams</li>
	</ul>


	<p><img src="Image205_zpsbeb496c2.jpg" style="width: 70%;" alt=""></p>


	<a name="What’s-a-“color-code”"></a>
<h2><strong>What’s a “color code”?</strong><a href="#What%E2%80%99s-a-%E2%80%9Ccolor-code%E2%80%9D" class="wiki-anchor">¶</a></h2>


	<p>A color code (CC) is two or more color tags placed close together.  
Pixy can detect and decode CCs and present them as special objects.  CCs
 are useful if you have lots of objects you want to detect and identify 
(i.e. more than could be detected with the seven separate color 
signatures alone.)</p>


	<p>A color code scheme with 2 tags and 4 different colors can 
differentiate up to 12 unique objects.  CCs with 3, 4 and 5 tags and/or 
more different colors are possible and can allow for many, many more 
unique objects.  (In fact, thousands of unique codes are possible by 
using CCs with 5 tags and 6 colors.)</p>


	<a name="Why-Color-Codes"></a>
<h2><strong>Why Color Codes?</strong><a href="#Why-Color-Codes" class="wiki-anchor">¶</a></h2>


	<p>CCs are useful if you have lots of objects you want to detect and 
identify, more than could be detected with the seven separate color 
signatures alone. CCs also improve detection accuracy by decreasing 
false detections.  That is, there is a low probability that specific 
colors will occur both in a specific order and close together.  The 
drawback is that you need to place a CC on each object you’re interested
 in detecting.  Often the object you’re interested in (yellow ball, 
purple toy) has a unique color signature and CCs aren’t needed.  Objects
 with CCs and objects without CCs can be used side-by-side with no 
problems, so you are free to use CCs for some objects and not others.</p>


	<p><img src="cc_zps767834e4.jpg" alt=""></p>


	<p>CCs give you an accurate angle estimate of the object (in addition 
to the position and size).  This is a computational “freebie” that some 
applications may find useful.  The angle estimate, decoded CCs, regular 
objects and all of their positions and sizes are provided at 50 frames 
per second.</p>


	<p>CCs might be particularly useful for helping a robot navigate.  For 
example, an indoor environment with CCs uniquely identifying each 
doorway and hallway would be both low-cost and robust.</p>


	<p><strong>For more information on Pixy, <a href="http://cmucam.org/projects/cmucam5/wiki">go here</a>.</strong></p>
  </div>
  <ul>
  
  
  
  </ul>

  
  
</div>

<div class="splitcontentright">
    
  <div class="members box">
    <h3>Members</h3>
    <p>
    Manager: <a href="http://cmucam.org/users/6">Anthony Rowe</a>, <a href="http://cmucam.org/users/166">Rich  LeGrand</a>, <a href="http://cmucam.org/users/182">Scott Robinson</a><br>
    </p>
  </div>
  


  
  <div class="news box">
    <h3>Latest news</h3>
    <p>
<a href="http://cmucam.org/news/18">September 30, 2015</a>
(377 comments)
<br>
<span class="summary">Pixy for LEGO</span><br>
<span class="author">Added by <a href="http://cmucam.org/users/1145">Edward Getz</a> <a href="http://cmucam.org/projects/cmucam5/activity?from=2015-10-06" title="10/06/2015 06:54 pm">over 2 years</a> ago</span></p>
<p>
<a href="http://cmucam.org/news/17">August 11, 2015</a>
(417 comments)
<br>

<span class="author">Added by <a href="http://cmucam.org/users/166">Rich  LeGrand</a> <a href="http://cmucam.org/projects/cmucam5/activity?from=2015-08-11" title="08/11/2015 09:58 am">over 2 years</a> ago</span></p>
<p>
<a href="http://cmucam.org/news/16">February 13, 2015</a>
(89 comments)
<br>

<span class="author">Added by <a href="http://cmucam.org/users/513">Jesse French</a> <a href="http://cmucam.org/projects/cmucam5/activity?from=2015-02-13" title="02/13/2015 04:47 pm">about 3 years</a> ago</span></p>
<p>
<a href="http://cmucam.org/news/15">January 23, 2015</a>
(72 comments)
<br>

<span class="author">Added by <a href="http://cmucam.org/users/513">Jesse French</a> <a href="http://cmucam.org/projects/cmucam5/activity?from=2015-02-13" title="02/13/2015 04:46 pm">about 3 years</a> ago</span></p>
<p>
<a href="http://cmucam.org/news/14">July 9, 2014</a>
(59 comments)
<br>

<span class="author">Added by <a href="http://cmucam.org/users/513">Jesse French</a> <a href="http://cmucam.org/projects/cmucam5/activity?from=2015-02-13" title="02/13/2015 04:46 pm">about 3 years</a> ago</span></p>

    <p><a href="http://cmucam.org/projects/cmucam5/news">View all news</a></p>
  </div>
  
  
</div>






        
        <div style="clear:both;"></div>
    </div>
</div>

<div id="ajax-indicator" style="display:none;"><span>Loading...</span></div>

<div id="footer">
  <div class="bgl"><div class="bgr">
    Powered by <a href="http://www.redmine.org/">Redmine</a> © 2006-2011 Jean-Philippe Lang
  </div></div>
</div>
</div>
</div>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-2903977-4']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>


</body></html>